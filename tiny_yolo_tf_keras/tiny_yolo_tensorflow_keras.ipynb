{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny Yolo - Keras - Tensorflow backend\n",
    "\n",
    "YOLO paper: Redmon et al., 2016 (https://arxiv.org/abs/1506.02640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Input, MaxPooling2D, BatchNormalization, Reshape, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from preprocessing import parse_annotation, BatchGenerator\n",
    "from yolo_utils import preprocess_image, decode_netout\n",
    "\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import wget\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tiny-yolo-voc-labels.txt', 'r') as f:\n",
    "    LABELS = [label.rstrip('\\n') for label in f.readlines()]\n",
    "\n",
    "ANCHORS = [1.08,1.19, 3.42,4.41, 6.63,11.38, 9.42,5.11, 16.62,10.52]\n",
    "\n",
    "IMAGE_H =  416\n",
    "IMAGE_W =  416\n",
    "CHANNELS = 3\n",
    "\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX = 5\n",
    "CLASS = len(LABELS)\n",
    "\n",
    "TRUE_BOX_BUFFER  = 50\n",
    "BATCH_SIZE       = 64\n",
    "\n",
    "EPSILON = 1e-8\n",
    "\n",
    "CLASS_WEIGHTS = np.ones(CLASS, dtype='float32')\n",
    "\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "WARM_UP_BATCHES  = 0\n",
    "\n",
    "DOWNLOAD_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, CHANNELS))\n",
    "true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
    "\n",
    "'''\n",
    "https://keras.io/layers/convolutional/\n",
    "\n",
    "Conv2D(filters, kernel_size, strides=(1, 1), padding='valid',      \\\n",
    "     data_format=None, dilation_rate=(1, 1), activation=None,      \\\n",
    "     use_bias=True, kernel_initializer='glorot_uniform',           \\\n",
    "     bias_initializer='zeros', kernel_regularizer=None,            \\\n",
    "     bias_regularizer=None, activity_regularizer=None,             \\\n",
    "     kernel_constraint=None, bias_constraint=None)\n",
    "     \n",
    "https://keras.io/layers/normalization/#batchnormalization\n",
    "\n",
    "BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,          \\\n",
    "    center=True, scale=True, beta_initializer='zeros',             \\\n",
    "    gamma_initializer='ones', moving_mean_initializer='zeros',     \\\n",
    "    moving_variance_initializer='ones', beta_regularizer=None,     \\\n",
    "    gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "\n",
    "https://keras.io/layers/advanced-activations/#leakyrelu\n",
    "\n",
    "LeakyReLU(alpha=0.3) \n",
    "It allows a small gradient when the unit is not active: f(x) = alpha * x for x < 0, f(x) = x for x >= 0\n",
    "\n",
    "https://keras.io/layers/pooling/#maxpooling2d\n",
    "\n",
    "MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
    "\n",
    "https://keras.io/layers/core/    -- Reshape\n",
    "\n",
    "Reshape(target_shape)\n",
    "'''\n",
    "# Layer 1\n",
    "X = Conv2D(filters=16, kernel_size=(3,3), padding='same', use_bias=False, name='conv_1')(input_image)\n",
    "X = BatchNormalization(name='norm_1')(X)\n",
    "X = LeakyReLU(alpha=0.1)(X)\n",
    "X = MaxPooling2D()(X)\n",
    "\n",
    "# Layer 2\n",
    "X = Conv2D(filters=32, kernel_size=(3,3), padding='same', use_bias=False, name='conv_2')(X)\n",
    "X = BatchNormalization(name='norm_2')(X)\n",
    "X = LeakyReLU(alpha=0.1)(X)\n",
    "X = MaxPooling2D()(X)\n",
    "\n",
    "# Layer 3\n",
    "X = Conv2D(filters=64, kernel_size=(3,3), padding='same', use_bias=False, name='conv_3')(X)\n",
    "X = BatchNormalization(name='norm_3')(X)\n",
    "X = LeakyReLU(alpha=0.1)(X)\n",
    "X = MaxPooling2D()(X)\n",
    "\n",
    "# Layer 4\n",
    "X = Conv2D(filters=128, kernel_size=(3,3), padding='same', use_bias=False, name='conv_4')(X)\n",
    "X = BatchNormalization(name='norm_4')(X)\n",
    "X = LeakyReLU(alpha=0.1)(X)\n",
    "X = MaxPooling2D()(X)\n",
    "\n",
    "# Layer 5\n",
    "X = Conv2D(filters=256, kernel_size=(3,3), padding='same', use_bias=False, name='conv_5')(X)\n",
    "X = BatchNormalization(name='norm_5')(X)\n",
    "X = LeakyReLU(alpha=0.1)(X)\n",
    "X = MaxPooling2D()(X)\n",
    "\n",
    "# Layer 6\n",
    "X = Conv2D(filters=512, kernel_size=(3,3), padding='same', use_bias=False, name='conv_6')(X)\n",
    "X = BatchNormalization(name='norm_6')(X)\n",
    "X = LeakyReLU(alpha=0.1)(X)\n",
    "X = MaxPooling2D(strides=(1,1), padding='same')(X)\n",
    "\n",
    "# Layer 7\n",
    "X = Conv2D(filters=1024, kernel_size=(3,3), padding='same', use_bias=False, name='conv_7')(X)\n",
    "X = BatchNormalization(name='norm_7')(X)\n",
    "X = LeakyReLU(alpha=0.1)(X)\n",
    "\n",
    "# Layer 8\n",
    "X = Conv2D(filters=1024, kernel_size=(3,3), padding='same', use_bias=False, name='conv_8')(X)\n",
    "X = BatchNormalization(name='norm_8')(X)\n",
    "X = LeakyReLU(alpha=0.1)(X)\n",
    "\n",
    "# Layer 9\n",
    "# BOX=5, CLASS=20, GRID_H=13, GRID_W=13\n",
    "X = Conv2D(BOX * (4 + 1 + CLASS), kernel_size=(1, 1), kernel_initializer='he_normal')(X)\n",
    "Y = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(X)       # X = [None, 13, 13, 125], Y = [None, 13, 13, 5, 25]\n",
    "\n",
    "# small hack to allow true_boxes to be registered when Keras build the model \n",
    "# for more information: https://github.com/fchollet/keras/issues/2790\n",
    "#Y = Lambda(lambda args: args[0])([Y, true_boxes])\n",
    "\n",
    "# Create model\n",
    "model = Model([input_image, true_boxes], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 416, 416, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 416, 416, 16)      432       \n",
      "_________________________________________________________________\n",
      "norm_1 (BatchNormalization)  (None, 416, 416, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 416, 416, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 208, 208, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 208, 208, 32)      4608      \n",
      "_________________________________________________________________\n",
      "norm_2 (BatchNormalization)  (None, 208, 208, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 208, 208, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 104, 104, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 104, 104, 64)      18432     \n",
      "_________________________________________________________________\n",
      "norm_3 (BatchNormalization)  (None, 104, 104, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 104, 104, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 52, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 52, 52, 128)       73728     \n",
      "_________________________________________________________________\n",
      "norm_4 (BatchNormalization)  (None, 52, 52, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 52, 52, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 26, 26, 256)       294912    \n",
      "_________________________________________________________________\n",
      "norm_5 (BatchNormalization)  (None, 26, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 13, 13, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "norm_6 (BatchNormalization)  (None, 13, 13, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 13, 13, 1024)      4718592   \n",
      "_________________________________________________________________\n",
      "norm_7 (BatchNormalization)  (None, 13, 13, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 13, 13, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv_8 (Conv2D)              (None, 13, 13, 1024)      9437184   \n",
      "_________________________________________________________________\n",
      "norm_8 (BatchNormalization)  (None, 13, 13, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 13, 13, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 125)       128125    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 13, 13, 5, 25)     0         \n",
      "=================================================================\n",
      "Total params: 15,867,885\n",
      "Trainable params: 15,861,773\n",
      "Non-trainable params: 6,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update network with pre-trained weights (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "if(os.path.isdir(\"weights\")):\n",
    "    if(os.path.exists(\"weights/yolov2-tiny-voc.weights\")):\n",
    "        print(\"file already exists\")\n",
    "    else:\n",
    "        os.chdir(\"weights/\")\n",
    "        url = 'https://pjreddie.com/media/files/yolov2-tiny-voc.weights'\n",
    "        wget.download(url)\n",
    "        os.chdir(\"../\")\n",
    "else:\n",
    "    os.makedirs(\"weights\")\n",
    "    os.chdir(\"weights/\")\n",
    "    url = 'https://pjreddie.com/media/files/yolov2-tiny-voc.weights'\n",
    "    wget.download(url)\n",
    "    os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weight_reader:\n",
    "    def __init__(self, weight_file):\n",
    "        self.offset = 4\n",
    "        self.all_weights = np.fromfile(weight_file, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        read = self.all_weights[self.offset : self.offset + size]\n",
    "        self.offset = self.offset + size\n",
    "        return read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with pre-trained weights.\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('weights/yolov2-tiny-voc.weights')):\n",
    "    wr = weight_reader('weights/yolov2-tiny-voc.weights')\n",
    "    conv_ = 8\n",
    "    \n",
    "    for i in range(1, conv_ + 1):\n",
    "        conv_layer = model.get_layer('conv_' + str(i))\n",
    "    \n",
    "        if i < conv_:\n",
    "            norm_layer = model.get_layer('norm_' + str(i))\n",
    "            size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "        \n",
    "            beta  = wr.read_bytes(size)\n",
    "            gamma = wr.read_bytes(size)\n",
    "            mean  = wr.read_bytes(size)\n",
    "            var   = wr.read_bytes(size)\n",
    "        \n",
    "            weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "        \n",
    "        if len(conv_layer.get_weights()) > 1:\n",
    "            bias   = wr.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "            kernel = wr.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "            kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "            kernel = kernel.transpose([2,3,1,0])\n",
    "            conv_layer.set_weights([kernel, bias])\n",
    "        else:\n",
    "            kernel = wr.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "            kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "            kernel = kernel.transpose([2,3,1,0])\n",
    "            conv_layer.set_weights([kernel])\n",
    "        \n",
    "    print('Model loaded with pre-trained weights.')\n",
    "else:\n",
    "    print('Weights file doesn\\'t exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with pre-trained weights.\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('CheckPoint/weights.10-1.57.hdf5')):\n",
    "    from keras.models import load_model\n",
    "    model.load_weights('CheckPoint/weights.10-1.57.hdf5')\n",
    "    print('Model loaded with pre-trained weights.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (DOWNLOAD_DATA == True):\n",
    "    # Save current directory path\n",
    "    curr_dir = os.getcwd()\n",
    "\n",
    "    # Training Data\n",
    "    if(os.path.isdir(\"data\") and os.path.exists(\"data/train2014.zip\")):\n",
    "        if(os.path.isdir(\"data/Ext/images/train2014\") and len(os.listdir('data/Ext/images/train2014')) != 0):\n",
    "            print('Training files available on disk.')\n",
    "        else:\n",
    "            with zipfile.ZipFile(\"data/train2014.zip\", 'r') as zip_ref:\n",
    "                zip_ref.extractall(\"data/Ext/images/\")\n",
    "    else:\n",
    "        if(os.path.isdir(\"data\")):\n",
    "            os.chdir(\"data/\")\n",
    "        else:\n",
    "            os.makedirs(\"data/Ext/images\")\n",
    "            os.chdir(\"data/\")\n",
    "        url = 'http://images.cocodataset.org/zips/train2014.zip'\n",
    "        filename = wget.download(url)\n",
    "        with zipfile.ZipFile(\"train2014.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./Ext/images\")\n",
    "\n",
    "    os.chdir(curr_dir)\n",
    "\n",
    "    # Training Data Annotation\n",
    "    if(os.path.isdir(\"data\") and os.path.exists(\"data/annotations_trainval2014.zip\")):\n",
    "        if(os.path.isdir(\"data/Ext/annotations\") and len(os.listdir('data/Ext/annotations')) != 0):\n",
    "            print('Training annotation files available on disk.')\n",
    "        else:\n",
    "            with zipfile.ZipFile(\"data/annotations_trainval2014.zip\", 'r') as zip_ref:\n",
    "                zip_ref.extractall(\"data/Ext/\")\n",
    "    else:\n",
    "        if(os.path.isdir(\"data\")):\n",
    "            os.chdir(\"data/\")\n",
    "        else:\n",
    "            os.makedirs(\"data\")\n",
    "            os.chdir(\"data/\")\n",
    "        url = 'http://images.cocodataset.org/annotations/annotations_trainval2014.zip'\n",
    "        filename = wget.download(url)\n",
    "        with zipfile.ZipFile(\"annotations_trainval2014.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./Ext/\")\n",
    "\n",
    "    os.chdir(curr_dir)\n",
    "\n",
    "    # Validation/Testing Data Annotation\n",
    "    if(os.path.isdir(\"data\") and os.path.exists(\"data/val2014.zip\")):\n",
    "        if(os.path.isdir(\"data/Ext/images/val2014\") and len(os.listdir('data/Ext/images/val2014')) != 0):\n",
    "            print('Validation / Testing files available on disk.')\n",
    "        else:\n",
    "            with zipfile.ZipFile(\"data/val2014.zip\", 'r') as zip_ref:\n",
    "                zip_ref.extractall(\"data/Ext/images/\")\n",
    "    else:\n",
    "        if(os.path.isdir(\"data\")):\n",
    "            os.chdir(\"data/\")\n",
    "        else:\n",
    "            os.makedirs(\"data\")\n",
    "            os.chdir(\"data/\")\n",
    "        url = 'http://images.cocodataset.org/zips/val2014.zip'\n",
    "        filename = wget.download(url)\n",
    "        with zipfile.ZipFile(\"val2014.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./Ext/images/\")\n",
    "\n",
    "    os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data from COCO format to VOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (DOWNLOAD_DATA == True):\n",
    "    os.makedirs(\"data/Ext/images/train2014ann\")\n",
    "    !python coco2pascal.py create_annotations data/Ext train data/Ext/images/train2014ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (DOWNLOAD_DATA == True):\n",
    "    os.makedirs(\"data/Ext/images/val2014ann\")\n",
    "    !python coco2pascal.py create_annotations data/Ext val data/Ext/images/val2014ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data   = \"data/Ext/images/train2014/\"\n",
    "training_data_ann = \"data/Ext/images/train2014ann/\"\n",
    "validation_data = \"data/Ext/images/val2014/\"\n",
    "validation_data_ann = \"data/Ext/images/val2014ann/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse annotations to generator training and validation generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_config = {\n",
    "    'IMAGE_H'          : IMAGE_H,\n",
    "    'IMAGE_W'          : IMAGE_W,\n",
    "    'GRID_H'           : GRID_H,\n",
    "    'GRID_W'           : GRID_W,\n",
    "    'BOX'              : BOX,\n",
    "    'LABELS'           : LABELS,\n",
    "    'CLASS'            : len(LABELS),\n",
    "    'ANCHORS'          : ANCHORS,\n",
    "    'BATCH_SIZE'       : (BATCH_SIZE * 10),\n",
    "    'TRUE_BOX_BUFFER'  : TRUE_BOX_BUFFER,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, seen_train_labels = parse_annotation(training_data_ann, \\\n",
    "                                                 training_data,     \\\n",
    "                                                 labels=LABELS)\n",
    "\n",
    "train_batch = BatchGenerator(train_imgs, gen_config, norm=normalize)\n",
    "\n",
    "\n",
    "valid_imgs, seen_valid_labels = parse_annotation(validation_data_ann, \\\n",
    "                                                 validation_data,     \\\n",
    "                                                 labels=LABELS)\n",
    "\n",
    "valid_batch = BatchGenerator(valid_imgs, gen_config, norm=normalize, jitter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3d3a6374539d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseen_train_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_annotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_ann\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m                                                      \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'normalize' is not defined"
     ]
    }
   ],
   "source": [
    "train_imgs, seen_train_labels = parse_annotation(training_data_ann, \\\n",
    "                                                 training_data,     \\\n",
    "                                                 labels=LABELS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = BatchGenerator(train_imgs, gen_config, norm=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 0\n",
    "for [X1, X2], Y in train_batch:\n",
    "    np.savez('data/Ext/images/train2014npz/np-{0:0=5d}.npz'.format(train), X1=X1, X2=X2, Y=Y)\n",
    "    train += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = 0\n",
    "for [X1, X2], Y in valid_batch:\n",
    "    np.savez('data/Ext/images/valid2014npz/np-{0:0=5d}.npz'.format(train), X1=X1, Y=Y)\n",
    "    train += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 480 480\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "cuDNN Backward Filter function launch failure : input shape([64,1024,13,13]) filter shape([3,3,1024,1024])\n\t [[{{node training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropFilter}} = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](leaky_re_lu_15/LeakyRelu, ConstantFolding/training_2/Adam/gradients/conv_8_1/convolution_grad/ShapeN-matshapes-1, training_2/Adam/gradients/AddN_7)]]\n\nCaused by op 'training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropFilter', defined at:\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-619306285757>\", line 11, in <module>\n    model.fit([X1[0], X2[0]], Y[0], batch_size=64, epochs=10, verbose=2)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1682, in fit\n    self._make_train_function()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 992, in _make_train_function\n    loss=self.total_loss)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py\", line 445, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2519, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 596, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 776, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 398, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 776, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 526, in _Conv2DGrad\n    data_format=data_format)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1192, in conv2d_backprop_filter\n    dilations=dilations, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'conv_8_1/convolution', defined at:\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 22 identical lines from previous traceback]\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-72f8d8745267>\", line 77, in <module>\n    X = Conv2D(filters=1024, kernel_size=(3,3), padding='same', use_bias=False, name='conv_8')(X)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3341, in conv2d\n    data_format=tf_data_format)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 781, in convolution\n    return op(input, filter)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 869, in __call__\n    return self.conv_op(inp, filter)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 521, in __call__\n    return self.call(inp, filter)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 205, in __call__\n    name=self.name)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1044, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): cuDNN Backward Filter function launch failure : input shape([64,1024,13,13]) filter shape([3,3,1024,1024])\n\t [[{{node training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropFilter}} = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](leaky_re_lu_15/LeakyRelu, ConstantFolding/training_2/Adam/gradients/conv_8_1/convolution_grad/ShapeN-matshapes-1, training_2/Adam/gradients/AddN_7)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: cuDNN Backward Filter function launch failure : input shape([64,1024,13,13]) filter shape([3,3,1024,1024])\n\t [[{{node training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropFilter}} = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](leaky_re_lu_15/LeakyRelu, ConstantFolding/training_2/Adam/gradients/conv_8_1/convolution_grad/ShapeN-matshapes-1, training_2/Adam/gradients/AddN_7)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-619306285757>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[0;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: cuDNN Backward Filter function launch failure : input shape([64,1024,13,13]) filter shape([3,3,1024,1024])\n\t [[{{node training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropFilter}} = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](leaky_re_lu_15/LeakyRelu, ConstantFolding/training_2/Adam/gradients/conv_8_1/convolution_grad/ShapeN-matshapes-1, training_2/Adam/gradients/AddN_7)]]\n\nCaused by op 'training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropFilter', defined at:\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-619306285757>\", line 11, in <module>\n    model.fit([X1[0], X2[0]], Y[0], batch_size=64, epochs=10, verbose=2)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1682, in fit\n    self._make_train_function()\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 992, in _make_train_function\n    loss=self.total_loss)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py\", line 445, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2519, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 596, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 776, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 398, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 776, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 526, in _Conv2DGrad\n    data_format=data_format)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1192, in conv2d_backprop_filter\n    dilations=dilations, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'conv_8_1/convolution', defined at:\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 22 identical lines from previous traceback]\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-72f8d8745267>\", line 77, in <module>\n    X = Conv2D(filters=1024, kernel_size=(3,3), padding='same', use_bias=False, name='conv_8')(X)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3341, in conv2d\n    data_format=tf_data_format)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 781, in convolution\n    return op(input, filter)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 869, in __call__\n    return self.conv_op(inp, filter)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 521, in __call__\n    return self.call(inp, filter)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 205, in __call__\n    name=self.name)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1044, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): cuDNN Backward Filter function launch failure : input shape([64,1024,13,13]) filter shape([3,3,1024,1024])\n\t [[{{node training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropFilter}} = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/gradients/conv_8_1/convolution_grad/Conv2DBackpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](leaky_re_lu_15/LeakyRelu, ConstantFolding/training_2/Adam/gradients/conv_8_1/convolution_grad/ShapeN-matshapes-1, training_2/Adam/gradients/AddN_7)]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    Y  = []\n",
    "    file = 'data/Ext/images/train2014npz/np-{0:0=5d}.npz'.format(i)\n",
    "    data = np.load(file)\n",
    "    X1.append(data['X1'])\n",
    "    X2.append(data['X2'])\n",
    "    Y.append(data['Y'])\n",
    "    print(len(X1[0]), len(X2[0]), len(Y[0]))\n",
    "    model.fit([X1[0], X2[0]], Y[0], batch_size=64, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 1 - Classification Loss\n",
    "\n",
    "if an object is detected, the classification loss at each cell is the squared error of the class conditional probabilities for each loss:\n",
    "\n",
    "<img src=\"images/ClassificationLoss.png\" style=\"width:500px;height:250;\">\n",
    "<caption><center> <u> **Figure 1** </u>: **Classification Loss**<br> </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_loss(y_true, y_pred):\n",
    "\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    # true classification box\n",
    "    true_box_class = tf.argmax(y_true[...,5:], -1)\n",
    "    \n",
    "    # classification mask\n",
    "    class_mask = y_true[...,4] * tf.gather(CLASS_WEIGHTS, true_box_class)\n",
    "\n",
    "    # number of classification boxes\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "    \n",
    "    # predicted box\n",
    "    pred_box_class = y_pred[...,5:]\n",
    "\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    \n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + EPSILON)\n",
    "    \n",
    "    loss_class = tf.Print(loss_class, [loss_class], message='Loss Class \\t', summarize=1000)\n",
    "    \n",
    "    return loss_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Localization Loss\n",
    "\n",
    "The localization loss measures the errors in the predicted boundary box locations and sizes. We only count the box responsible for detecting the object.\n",
    "\n",
    "<img src=\"images/LocalizationLoss.png\" style=\"width:500px;height:250;\">\n",
    "<caption><center> <u> **Figure 2** </u>: **Localization Loss**<br> </center></caption>\n",
    "\n",
    "We do not want to weight absolute errors in large boxes and small boxes equally. i.e. a 2-pixel error in a large box is the same for a small box. To partially address this, YOLO predicts the square root of the bounding box width and height instead of the width and height. In addition, to put more emphasis on the boundary box accuracy, we multiply the loss by coord (default: 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
    "    \n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    seen = tf.Variable(0.)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically   \n",
    "    \n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1)\n",
    "    \n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    \n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
    "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
    "                                   tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy, \n",
    "                                   true_box_wh,\n",
    "                                   coord_mask])\n",
    "\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    \n",
    "    Localization_Loss = loss_xy + loss_wh\n",
    "    \n",
    "    # Localization_Loss = tf.Print(Localization_Loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
    "    # Localization_Loss = tf.Print(Localization_Loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
    "    \n",
    "    return Localization_Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Confidence Loss\n",
    "\n",
    "If an object is detected in the box, the confidence loss (measuring the objectness of the box) is:\n",
    "\n",
    "<img src=\"images/ConfidenceLoss1.png\" style=\"width:500px;height:250;\">\n",
    "<caption><center> <u> **Figure 3** </u>: **Confidence Loss**<br> </center></caption>\n",
    "\n",
    "If an object is not detected in the box, the confidence loss is:\n",
    "\n",
    "<img src=\"images/ConfidenceLoss2.png\" style=\"width:500px;height:250;\">\n",
    "<caption><center> <u> **Figure 4** </u>: **Confidence Loss**<br> </center></caption>\n",
    "\n",
    "Most boxes do not contain any objects. This causes a class imbalance problem, i.e. we train the model to detect background more frequently than detecting objects. To remedy this, we weight this loss down by a factor noobj (default: 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_loss(y_true, y_pred):\n",
    "    \n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
    "    \n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "    \n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "    \n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "    \n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "    \n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    \n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4])\n",
    "    \n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "\n",
    "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf - pred_box_conf) * conf_mask)  / (nb_conf_box  + EPSILON) / 2.\n",
    "    \n",
    "    # loss_conf = tf.Print(loss_conf, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
    "    \n",
    "    return loss_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Loss\n",
    "\n",
    "The final loss adds localization, confidence and classification losses together.\n",
    "\n",
    "<img src=\"images/TotalLoss.png\" style=\"width:500px;height:250;\">\n",
    "<caption><center> <u> **Figure 5** </u>: **Total Loss**<br> </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss(y_true, y_pred):\n",
    "    loss = classification_loss(y_true, y_pred) + localization_loss(y_true, y_pred) + confidence_loss(y_true, y_pred)\n",
    "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://keras.io/optimizers/\n",
    "\n",
    "Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "'''\n",
    "\n",
    "optimizer = Adam(lr=0.5e-4, epsilon=EPSILON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://keras.io/models/sequential/\n",
    "\n",
    "compile(optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, \\\n",
    "                                                        weighted_metrics=None, target_tensors=None)\n",
    "'''\n",
    "model.compile(loss=total_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check point directory exists.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "https://keras.io/callbacks/\n",
    "\n",
    "EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', \\\n",
    "                                                  baseline=None, restore_best_weights=False)\n",
    "\n",
    "ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False,  \\\n",
    "                                              save_weights_only=False, mode='auto', period=1)\n",
    "'''\n",
    "EarlyStop = EarlyStopping(min_delta=0.001, patience=5, mode='min', verbose=1)\n",
    "\n",
    "if(os.path.isdir(\"CheckPoint\")):\n",
    "    print('Check point directory exists.')\n",
    "else:\n",
    "    os.makedirs(\"CheckPoint\")\n",
    "\n",
    "MakeCheckPoint = ModelCheckpoint(\"CheckPoint/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", \\\n",
    "                                 verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 131/1425 [=>............................] - ETA: 40:12 - loss: 1.9482"
     ]
    }
   ],
   "source": [
    "'''\n",
    "https://keras.io/models/sequential/\n",
    "\n",
    "fit_generator(generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, \\\n",
    "                   validation_data=None, validation_steps=None, class_weight=None,  \\\n",
    "                   max_queue_size=10, workers=1, use_multiprocessing=False,         \\\n",
    "                   shuffle=True, initial_epoch=0)\n",
    "'''\n",
    "\n",
    "model.fit_generator(\n",
    "                    generator        = train_batch,\n",
    "                    steps_per_epoch  = len(train_batch),\n",
    "                    epochs           = 10,\n",
    "                    validation_data  = valid_batch,\n",
    "                    validation_steps = len(valid_batch),\n",
    "                    callbacks        = [EarlyStop, MakeCheckPoint],\n",
    "                    max_queue_size   = 10\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-max suppression ###\n",
    "\n",
    "Even after filtering by thresholding over the classes scores, you still end up a lot of overlapping boxes. A second filter for selecting the right boxes is called non-maximum suppression (NMS). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"images/non-max-suppression.png\" style=\"width:500px;height:400;\">\n",
    "<caption><center> <u> **Figure 5** </u>: In this example, the model has predicted 3 cars, but it's actually 3 predictions of the same car. Running non-max suppression (NMS) will select only the most accurate (highest probabiliy) one of the 3 boxes. <br> </center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-max suppression uses the very important function called **\"Intersection over Union\"**, or IoU.\n",
    "<img src=\"images/iou.png\" style=\"width:500px;height:400;\">\n",
    "<caption><center> <u> **Figure 6** </u>: Definition of \"Intersection over Union\". <br> </center></caption> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Tiny YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xmodel, image_file):\n",
    "\n",
    "    # Preprocess your image\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (IMAGE_H, IMAGE_W))\n",
    "\n",
    "\n",
    "    _array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
    "\n",
    "    netout = xmodel.predict([image_data, _array])\n",
    "\n",
    "    return netout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_network_output(netout):\n",
    "    return decode_netout(netout[0], \n",
    "                        anchors=ANCHORS, \n",
    "                        nb_class=CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell on the \"test.jpg\" image to verify that your function is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netout = predict(model, \"COCO_val2014_000000385918.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = decode_network_output(netout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in boxes:\n",
    "    print(LABELS[box.get_label()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**: The ideas presented in this notebook came primarily from the two YOLO papers. The implementation here also took significant inspiration and used many components from Allan Zelener's github repository. The pretrained weights used in this exercise came from the official YOLO website. \n",
    "- Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) (2015)\n",
    "- Joseph Redmon, Ali Farhadi - [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) (2016)\n",
    "- Allan Zelener - [YAD2K: Yet Another Darknet 2 Keras](https://github.com/allanzelener/YAD2K)\n",
    "- The official YOLO website (https://pjreddie.com/darknet/yolo/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_batch = BatchGenerator(train_imgs, gen_config, norm=normalize)\n",
    "\n",
    "\n",
    "\n",
    "valid_batch = BatchGenerator(valid_imgs, gen_config, norm=normalize, jitter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OMdut",
   "launcher_item_id": "bbBOL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
